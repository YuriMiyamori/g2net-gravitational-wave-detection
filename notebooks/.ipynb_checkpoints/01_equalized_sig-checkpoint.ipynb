{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames, CSV\n",
    "using NPZ\n",
    "using Random, Statistics\n",
    "using DSP,FFTW, AbstractFFTs,Interpolations\n",
    "using Wavelets, ContinuousWavelets\n",
    "using ProgressMeter\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot\n",
    "plt.style.use(\"seaborn-whitegrid\");\n",
    "rcParams = PyPlot.PyDict(PyPlot.matplotlib.\"rcParams\")\n",
    "rcParams[\"font.size\"] = 12\n",
    "rcParams[\"figure.figsize\"] = [16,16]\n",
    "rcParams[\"figure.dpi\"] = 220;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/yuri/kaggle/g2net-gravitational-wave-detection/dataset\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const BASE_DIR = \"/home/yuri/kaggle/g2net-gravitational-wave-detection/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fade! (generic function with 2 methods)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fade!(signal, fade_length=0.06)\n",
    "    n = length(signal)\n",
    "    n0 = floor(Int, length(signal) * fade_length)\n",
    "    n1 = n - n0\n",
    "    t = collect(1:n)\n",
    "\n",
    "    sigmoid(x)=1 ./(1 .+exp(-14 .*(x .-0.5)))\n",
    "    for i in 1:n0\n",
    "        signal[i] = signal[i] * sigmoid(i/n0)\n",
    "    end\n",
    "    for i in n1:n\n",
    "        signal[i] = signal[i] * sigmoid((n-i)/(n-n1))\n",
    "    end\n",
    "    signal\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_npy_data! (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function read_npy_data!(path, res, num)\n",
    "    data = npzread(path) |> x-> reshape(x, 3, sampling_rate*2) |> transpose |> Array\n",
    "    for i in 1:3\n",
    "        data[:,i] = fade!(data[:,i])\n",
    "        res[(num-1)*4096+1:num*4096,i] .= data[:,i]\n",
    "    end\n",
    "    # res = cat(res, data,dims=1)\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noise_detect (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function noise_detect(h, h̃, number_of_chunks, overlap_rate)\n",
    "    points_per_chunk = 2^floor(Int, log2(length(h)/number_of_chunks))\n",
    "\n",
    "    s = welch_pgram(h, points_per_chunk, floor(Int, points_per_chunk*overlap_rate), fs=sampling_rate, window=hanning)\n",
    "    f_noise, noise_welch = s.freq, s.power\n",
    "\n",
    "    noise_spectral_density = sqrt.(2 * length(h) .* noise_welch ./ sampling_rate)\n",
    "    nodes = (f_noise,)\n",
    "    itp = interpolate(nodes, noise_spectral_density, Gridded(Linear()))\n",
    "    noise_spectral_density_interpolator = itp(frequencies);\n",
    "\n",
    "    h̃_equalized = h̃ ./ noise_spectral_density_interpolator\n",
    "    h_equalized = (sampling_rate * FFTW.irfft(h̃_equalized, length(t)));\n",
    "\n",
    "    return h_equalized, h̃_equalized\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00048828125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const number_of_chunks = 16\n",
    "const sampling_rate = 2048\n",
    "const dt = 1 / sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function main(train_test)\n",
    "    out_path = joinpath(BASE_DIR, \"01_equalized/$(train_test)\")\n",
    "    base_input_dir = joinpath(BASE_DIR, \"00_row_data/$(train_test)\")\n",
    "\n",
    "    dir_0 = base_input_dir\n",
    "    @showprogress for f1 in readdir(dir_0, join=false)\n",
    "        dir_1 = joinpath(dir_0, f1)\n",
    "        for f2 in readdir(dir_1, join=false)\n",
    "            dir_2 = joinpath(dir_1, f2)\n",
    "            for f3 in readdir(dir_2, join=false)\n",
    "                dir_3 = joinpath(dir_2, f3)\n",
    "                file_names = readdir(dir_3, join=false)\n",
    "                file_size = length(file_names)\n",
    "                file_paths = String[]\n",
    "                for file_name in file_names\n",
    "                    push!(file_paths, joinpath(dir_3, file_name))\n",
    "                end\n",
    "\n",
    "                data = Array{Float64, 2}(undef, 4096*length(file_paths), 3)\n",
    "                for (num, file_path) in enumerate(file_paths)\n",
    "                    read_npy_data!(file_path, data, num)\n",
    "                end\n",
    "                ##  main\n",
    "                h_equalized_filtered_arr = Float32[]\n",
    "                for i in 1:3 ## LIGO LIGO Virgo\n",
    "                    h = data[:, i]\n",
    "                    global t = collect(1:length(h)) / sampling_rate\n",
    "                    global frequencies = FFTW.rfftfreq(length(h), sampling_rate)\n",
    "                    h̃ = dt * FFTW.rfft(h)\n",
    "                    h_equalized, h̃_equalized= noise_detect(h, h̃, number_of_chunks, 0.5)\n",
    "                    responsetype = Bandpass(35, 300, fs=sampling_rate)\n",
    "                    h_equalized_filtered = filt(digitalfilter(responsetype, Butterworth(4)), h_equalized)\n",
    "                    append!(h_equalized_filtered_arr, Float32.(h_equalized_filtered))\n",
    "                end\n",
    "                h_equalized_filtered_arr = reshape(h_equalized_filtered_arr, (Int(length(h_equalized_filtered_arr)/3), 3))\n",
    "                \n",
    "                for (i, file_name) in enumerate(file_names)\n",
    "                    s = 4096*(i-1)+1\n",
    "                    t = 4096*(i)\n",
    "                    save_arr = h_equalized_filtered_arr[s:t, :]\n",
    "                    save_name = \"$(split(file_name, '.')[1])_equalized.npy\"\n",
    "                    # @show(save_name)\n",
    "                    npzwrite(joinpath(out_path, save_name),save_arr |>  transpose |> Array)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_test in [\"train\", \"test\"]\n",
    "    main(train_test)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.4",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
