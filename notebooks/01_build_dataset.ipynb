{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames, DataFramesMeta, CSV\n",
    "using NPZ\n",
    "using Random, Statistics\n",
    "using DSP,FFTW #, AbstractFFTs,Interpolations\n",
    "# using Wavelets, ContinuousWavelets\n",
    "using ProgressMeter\n",
    "using BenchmarkTools\n",
    "\n",
    "using PyPlot\n",
    "ENV[\"COLUMNS\"] = 700\n",
    "plt.style.use(\"seaborn-whitegrid\");\n",
    "rcParams = PyPlot.PyDict(PyPlot.matplotlib.\"rcParams\")\n",
    "rcParams[\"font.size\"] = 12\n",
    "rcParams[\"figure.figsize\"] = [16,16]\n",
    "rcParams[\"figure.dpi\"] = 220;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/yuri/kaggle/g2net-gravitational-wave-detection/\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_DIR = \"/home/yuri/kaggle/g2net-gravitational-wave-detection/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00048828125"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_df = CSV.read(joinpath(BASE_DIR, \"training_labels.csv\"), DataFrame)\n",
    "train_label_df[:, :fname] = train_label_df[:, :id] .* \".npy\"\n",
    "const sampling_rate = 2048\n",
    "const dt = 1 / sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>560,000 rows × 3 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>target</th><th>fname</th></tr><tr><th></th><th title=\"String\">String</th><th title=\"Int64\">Int64</th><th title=\"String\">String</th></tr></thead><tbody><tr><th>1</th><td>00000e74ad</td><td>1</td><td>00000e74ad.npy</td></tr><tr><th>2</th><td>00001f4945</td><td>0</td><td>00001f4945.npy</td></tr><tr><th>3</th><td>0000661522</td><td>0</td><td>0000661522.npy</td></tr><tr><th>4</th><td>00007a006a</td><td>0</td><td>00007a006a.npy</td></tr><tr><th>5</th><td>0000a38978</td><td>1</td><td>0000a38978.npy</td></tr><tr><th>6</th><td>0000bb9f3e</td><td>1</td><td>0000bb9f3e.npy</td></tr><tr><th>7</th><td>0000c3b9c9</td><td>0</td><td>0000c3b9c9.npy</td></tr><tr><th>8</th><td>0000d61b7b</td><td>1</td><td>0000d61b7b.npy</td></tr><tr><th>9</th><td>0001016d12</td><td>1</td><td>0001016d12.npy</td></tr><tr><th>10</th><td>00010beb4a</td><td>1</td><td>00010beb4a.npy</td></tr><tr><th>11</th><td>000118b40d</td><td>0</td><td>000118b40d.npy</td></tr><tr><th>12</th><td>0001388506</td><td>1</td><td>0001388506.npy</td></tr><tr><th>13</th><td>00014b7a9d</td><td>1</td><td>00014b7a9d.npy</td></tr><tr><th>14</th><td>0001616241</td><td>0</td><td>0001616241.npy</td></tr><tr><th>15</th><td>00017d3cf3</td><td>1</td><td>00017d3cf3.npy</td></tr><tr><th>16</th><td>0001808ecc</td><td>1</td><td>0001808ecc.npy</td></tr><tr><th>17</th><td>0001bfda2f</td><td>0</td><td>0001bfda2f.npy</td></tr><tr><th>18</th><td>0001c76f56</td><td>1</td><td>0001c76f56.npy</td></tr><tr><th>19</th><td>0002014fd3</td><td>0</td><td>0002014fd3.npy</td></tr><tr><th>20</th><td>0002402e11</td><td>0</td><td>0002402e11.npy</td></tr><tr><th>21</th><td>000243542d</td><td>0</td><td>000243542d.npy</td></tr><tr><th>22</th><td>00025c4117</td><td>0</td><td>00025c4117.npy</td></tr><tr><th>23</th><td>00026119ef</td><td>1</td><td>00026119ef.npy</td></tr><tr><th>24</th><td>00026ce3c5</td><td>0</td><td>00026ce3c5.npy</td></tr><tr><th>25</th><td>000270b7cc</td><td>1</td><td>000270b7cc.npy</td></tr><tr><th>26</th><td>0002729283</td><td>0</td><td>0002729283.npy</td></tr><tr><th>27</th><td>0002738423</td><td>0</td><td>0002738423.npy</td></tr><tr><th>28</th><td>000288e4a5</td><td>1</td><td>000288e4a5.npy</td></tr><tr><th>29</th><td>000295765e</td><td>0</td><td>000295765e.npy</td></tr><tr><th>30</th><td>0002b64784</td><td>1</td><td>0002b64784.npy</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& id & target & fname\\\\\n",
       "\t\\hline\n",
       "\t& String & Int64 & String\\\\\n",
       "\t\\hline\n",
       "\t1 & 00000e74ad & 1 & 00000e74ad.npy \\\\\n",
       "\t2 & 00001f4945 & 0 & 00001f4945.npy \\\\\n",
       "\t3 & 0000661522 & 0 & 0000661522.npy \\\\\n",
       "\t4 & 00007a006a & 0 & 00007a006a.npy \\\\\n",
       "\t5 & 0000a38978 & 1 & 0000a38978.npy \\\\\n",
       "\t6 & 0000bb9f3e & 1 & 0000bb9f3e.npy \\\\\n",
       "\t7 & 0000c3b9c9 & 0 & 0000c3b9c9.npy \\\\\n",
       "\t8 & 0000d61b7b & 1 & 0000d61b7b.npy \\\\\n",
       "\t9 & 0001016d12 & 1 & 0001016d12.npy \\\\\n",
       "\t10 & 00010beb4a & 1 & 00010beb4a.npy \\\\\n",
       "\t11 & 000118b40d & 0 & 000118b40d.npy \\\\\n",
       "\t12 & 0001388506 & 1 & 0001388506.npy \\\\\n",
       "\t13 & 00014b7a9d & 1 & 00014b7a9d.npy \\\\\n",
       "\t14 & 0001616241 & 0 & 0001616241.npy \\\\\n",
       "\t15 & 00017d3cf3 & 1 & 00017d3cf3.npy \\\\\n",
       "\t16 & 0001808ecc & 1 & 0001808ecc.npy \\\\\n",
       "\t17 & 0001bfda2f & 0 & 0001bfda2f.npy \\\\\n",
       "\t18 & 0001c76f56 & 1 & 0001c76f56.npy \\\\\n",
       "\t19 & 0002014fd3 & 0 & 0002014fd3.npy \\\\\n",
       "\t20 & 0002402e11 & 0 & 0002402e11.npy \\\\\n",
       "\t21 & 000243542d & 0 & 000243542d.npy \\\\\n",
       "\t22 & 00025c4117 & 0 & 00025c4117.npy \\\\\n",
       "\t23 & 00026119ef & 1 & 00026119ef.npy \\\\\n",
       "\t24 & 00026ce3c5 & 0 & 00026ce3c5.npy \\\\\n",
       "\t25 & 000270b7cc & 1 & 000270b7cc.npy \\\\\n",
       "\t26 & 0002729283 & 0 & 0002729283.npy \\\\\n",
       "\t27 & 0002738423 & 0 & 0002738423.npy \\\\\n",
       "\t28 & 000288e4a5 & 1 & 000288e4a5.npy \\\\\n",
       "\t29 & 000295765e & 0 & 000295765e.npy \\\\\n",
       "\t30 & 0002b64784 & 1 & 0002b64784.npy \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m560000×3 DataFrame\u001b[0m\n",
       "\u001b[1m    Row \u001b[0m│\u001b[1m id         \u001b[0m\u001b[1m target \u001b[0m\u001b[1m fname          \u001b[0m\n",
       "\u001b[1m        \u001b[0m│\u001b[90m String     \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m String         \u001b[0m\n",
       "────────┼────────────────────────────────────\n",
       "      1 │ 00000e74ad       1  00000e74ad.npy\n",
       "      2 │ 00001f4945       0  00001f4945.npy\n",
       "      3 │ 0000661522       0  0000661522.npy\n",
       "      4 │ 00007a006a       0  00007a006a.npy\n",
       "      5 │ 0000a38978       1  0000a38978.npy\n",
       "      6 │ 0000bb9f3e       1  0000bb9f3e.npy\n",
       "      7 │ 0000c3b9c9       0  0000c3b9c9.npy\n",
       "      8 │ 0000d61b7b       1  0000d61b7b.npy\n",
       "      9 │ 0001016d12       1  0001016d12.npy\n",
       "     10 │ 00010beb4a       1  00010beb4a.npy\n",
       "     11 │ 000118b40d       0  000118b40d.npy\n",
       "   ⋮    │     ⋮         ⋮           ⋮\n",
       " 559991 │ ffff476c4b       0  ffff476c4b.npy\n",
       " 559992 │ ffff5c861a       0  ffff5c861a.npy\n",
       " 559993 │ ffff6cfc4f       0  ffff6cfc4f.npy\n",
       " 559994 │ ffff870a41       0  ffff870a41.npy\n",
       " 559995 │ ffff8ae576       1  ffff8ae576.npy\n",
       " 559996 │ ffff9a5645       1  ffff9a5645.npy\n",
       " 559997 │ ffffab0c27       0  ffffab0c27.npy\n",
       " 559998 │ ffffcf161a       1  ffffcf161a.npy\n",
       " 559999 │ ffffd2c403       0  ffffd2c403.npy\n",
       " 560000 │ fffff2180b       0  fffff2180b.npy\n",
       "\u001b[36m                          559979 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m139.403 μs\u001b[22m\u001b[39m … \u001b[35m 12.948 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m 0.00% … 93.68%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m338.354 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m397.155 μs\u001b[22m\u001b[39m ± \u001b[32m783.402 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m13.62% ±  6.70%\n",
       "\n",
       "  \u001b[34m█\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[34m█\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▁\n",
       "  688 μs\u001b[90m           Histogram: frequency by time\u001b[39m          287 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m679.67 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m137\u001b[39m."
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const max_safe_exponent = 700.0\n",
    "\n",
    "function fade!(signal, fade_length=0.06)\n",
    "    n = length(signal)\n",
    "    n0 = floor(Int, length(signal) * fade_length)\n",
    "    n1 = n - n0\n",
    "    t = collect(1:n)\n",
    "    \n",
    "    sigmoid(x)=1 ./(1 .+exp(-14 .*(x .-0.5)))\n",
    "    for i in 1:n0\n",
    "        signal[i] = signal[i] * sigmoid(i/n0)\n",
    "    end\n",
    "    for i in n1:n\n",
    "        signal[i] = signal[i] * sigmoid((n-i)/(n-n1))\n",
    "    end\n",
    "    signal\n",
    "end\n",
    "\n",
    "function read_npy_data!(path, res, num)\n",
    "    data = npzread(path) |> x-> reshape(x, 3, sampling_rate*2) |> transpose |> Array\n",
    "    for i in 1:3\n",
    "        data[:,i] = fade!(data[:,i])\n",
    "        res[(num-1)*4096+1:num*4096,i] .= data[:,i]\n",
    "    end\n",
    "    # res = cat(res, data,dims=1)\n",
    "end\n",
    "\n",
    "test_data = zeros(4096,3)\n",
    "@benchmark read_npy_data!(joinpath(BASE_DIR, \"train/0/0/0/00000e74ad.npy\"), test_data, 1)\n",
    "# plt.plot(1:4096, test_data[:, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noise_detect (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function noise_detect(h, h̃, number_of_chunks, overlap_rate)\n",
    "    points_per_chunk = 2^floor(Int, log2(length(h)/number_of_chunks))\n",
    "\n",
    "    s = welch_pgram(h, points_per_chunk, floor(Int, points_per_chunk*overlap_rate), fs=sampling_rate, window=hanning)\n",
    "    f_noise, noise_welch = s.freq, s.power\n",
    "\n",
    "    noise_spectral_density = sqrt.(2 * length(h) .* noise_welch ./ sampling_rate)\n",
    "    nodes = (f_noise,)\n",
    "    itp = interpolate(nodes, noise_spectral_density, Gridded(Linear()))\n",
    "    noise_spectral_density_interpolator = itp(frequencies);\n",
    "\n",
    "    h̃_equalized = h̃ ./ noise_spectral_density_interpolator\n",
    "    h_equalized = (sampling_rate * FFTW.irfft(h̃_equalized, length(t)));\n",
    "\n",
    "    return h_equalized, h̃_equalized\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_in_sig([\"00000e74ad.npy\", \"00001f4945.npy\"], train_label_df, 1) = [\"00000e74ad.npy\"]\n",
      "check_in_sig([\"00000e74ad.npy\", \"00001f4945.npy\"], train_label_df, 0) = [\"00001f4945.npy\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{String,1}:\n",
       " \"00001f4945.npy\""
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function check_in_sig(fnames, df, target)\n",
    "    res = String[]\n",
    "    for fname in fnames\n",
    "        if first(df[df[!, :fname] .== fname, :target]) == target\n",
    "            push!(res, fname)\n",
    "        end\n",
    "    end\n",
    "    res\n",
    "end\n",
    "\n",
    "@show(check_in_sig([\"00000e74ad.npy\", \"00001f4945.npy\"], train_label_df, 1))\n",
    "@show(check_in_sig([\"00000e74ad.npy\", \"00001f4945.npy\"], train_label_df, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float16,1}:\n",
       " 1.2"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 1.2\n",
    "arr = Float16[]\n",
    "push!(arr,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length(readdir(joinpath(BASE_DIR, \"train\"), join = true)) = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:06:45\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "const number_of_chunks = 16\n",
    "function main(train_test)\n",
    "    out_path = joinpath(BASE_DIR, \"dataset/train_equalized\")\n",
    "    @show(length(readdir(joinpath(BASE_DIR, \"train\"), join=true)))\n",
    "    dir_0 = joinpath(BASE_DIR, train_test)\n",
    "    for f1 in readdir(dir_0, join=false)\n",
    "        dir_1 = joinpath(dir_0, f1)\n",
    "        @showprogress for f2 in readdir(dir_1, join=false)\n",
    "            dir_2 = joinpath(dir_1, f2)\n",
    "            for f3 in readdir(dir_2, join=false)\n",
    "                dir_3 = joinpath(dir_2, f3)\n",
    "                for (target, fname_add) in zip([1, 0], [\"in_sig.npy\", \"no_sig.npy\"]) \n",
    "                    file_names = readdir(dir_3, join=false)\n",
    "                    file_names = check_in_sig(file_names, train_label_df, target)\n",
    "                    file_paths = String[]\n",
    "                    # @show(target, file_names)\n",
    "                    for file_name in file_names\n",
    "                        push!(file_paths, joinpath(dir_3, file_name))\n",
    "                    end\n",
    "               \n",
    "                    data = Array{Float64, 2}(undef, 4096*length(file_paths), 3)\n",
    "                    for (num, file_path) in enumerate(file_paths)\n",
    "                        read_npy_data!(file_path, data, num)\n",
    "                    end\n",
    "                    ##  main\n",
    "                    h_equalized_filtered_arr = Float32[]\n",
    "                    h̃_equalized_filtered_arr = ComplexF32[]\n",
    "                    for i in 1:3 ## LIGO LIGO Virgo\n",
    "                        h = data[:, i]\n",
    "                        global t = collect(1:length(h)) / sampling_rate\n",
    "                        global frequencies = FFTW.rfftfreq(length(h), sampling_rate)\n",
    "                        h̃ = dt * FFTW.rfft(h) \n",
    "                        h_equalized, h̃_equalized= noise_detect(h, h̃, number_of_chunks, 0.5)\n",
    "                        responsetype = Bandpass(35, 300, fs=sampling_rate)\n",
    "                        h_equalized_filtered = filt(digitalfilter(responsetype, Butterworth(4)), h_equalized)\n",
    "                        h̃_equalized_filtered = dt * FFTW.rfft(h_equalized_filtered) \n",
    "                        # @show(size(h))\n",
    "                        # @show(size(h̃))\n",
    "                        # @show(size(h_equalized_filtered))\n",
    "                        # @show(size(h̃_equalized_filtered))\n",
    "                        append!(h_equalized_filtered_arr, Float32.(h_equalized_filtered))\n",
    "                        append!(h̃_equalized_filtered_arr, ComplexF32.(h̃_equalized_filtered))\n",
    "                    end\n",
    "                    h_equalized_filtered_arr = reshape(h_equalized_filtered_arr, (Int(length(h_equalized_filtered_arr)/3), 3))\n",
    "                    h̃_equalized_filtered_arr = reshape(h̃_equalized_filtered_arr, (Int(length(h̃_equalized_filtered_arr)/3), 3))\n",
    "                    # save_output\n",
    "                    # split each npy file and save\n",
    "                    # @show(size(h_equalized_filtered_arr))\n",
    "                    npzwrite(joinpath(out_path, \"$(f1)_$(f2)_$(f3)_$(fname_add)\"), \n",
    "                        h_equalized_filtered_arr |>  transpose |> Array)\n",
    "                    end # target, fname_add\n",
    "                end # f3\n",
    "        end\n",
    "        return \n",
    "    end\n",
    "end\n",
    " \n",
    "main(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [\"abc\", \"cdf.npy\"]\n",
    "\"cdf.npy\" in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4096 * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const number_of_chunks = 16\n",
    "function main(train_test)\n",
    "    out_path = joinpath(BASE_DIR, \"dataset/train_equalized\")\n",
    "    @show(length(readdir(joinpath(BASE_DIR, \"train\"), join=true)))\n",
    "    dir_0 = joinpath(BASE_DIR, train_test)\n",
    "    for f1 in readdir(dir_0, join=false)\n",
    "        dir_1 = joinpath(dir_0, f1)\n",
    "        @showprogress for f2 in readdir(dir_1, join=false)\n",
    "            dir_2 = joinpath(dir_1, f2)\n",
    "            for f3 in readdir(dir_2, join=false)\n",
    "                dir_3 = joinpath(dir_2, f3)\n",
    "                for (target, fname_add) in zip([1, 0], [\"in_sig.npy\", \"no_sig.npy\"]) \n",
    "                    file_names = readdir(dir_3, join=false)\n",
    "                    file_names = check_in_sig(file_names, train_label_df, target)\n",
    "                    file_paths = String[]\n",
    "                    # @show(target, file_names)\n",
    "                    for file_name in file_names\n",
    "                        push!(file_paths, joinpath(dir_3, file_name))\n",
    "                    end\n",
    "               \n",
    "                    data = Array{Float64, 2}(undef, 4096*length(file_paths), 3)\n",
    "                    for (num, file_path) in enumerate(file_paths)\n",
    "                        read_npy_data!(file_path, data, num)\n",
    "                    end\n",
    "                    ##  main\n",
    "                    h_equalized_filtered_arr = Float32[]\n",
    "                    h̃_equalized_filtered_arr = ComplexF32[]\n",
    "                    for i in 1:3 ## LIGO LIGO Virgo\n",
    "                        h = data[:, i]\n",
    "                        global t = collect(1:length(h)) / sampling_rate\n",
    "                        global frequencies = FFTW.rfftfreq(length(h), sampling_rate)\n",
    "                        h̃ = dt * FFTW.rfft(h) \n",
    "                        h_equalized, h̃_equalized= noise_detect(h, h̃, number_of_chunks, 0.5)\n",
    "                        responsetype = Bandpass(35, 300, fs=sampling_rate)\n",
    "                        h_equalized_filtered = filt(digitalfilter(responsetype, Butterworth(4)), h_equalized)\n",
    "                        h̃_equalized_filtered = dt * FFTW.rfft(h_equalized_filtered) \n",
    "                        append!(h_equalized_filtered_arr, Float32.(h_equalized_filtered))\n",
    "                        append!(h̃_equalized_filtered_arr, ComplexF32.(h̃_equalized_filtered))\n",
    "                    end\n",
    "                    h_equalized_filtered_arr = reshape(h_equalized_filtered_arr, (Int(length(h_equalized_filtered_arr)/3), 3))\n",
    "                    h̃_equalized_filtered_arr = reshape(h̃_equalized_filtered_arr, (Int(length(h̃_equalized_filtered_arr)/3), 3))\n",
    "                    npzwrite(joinpath(out_path, \"$(f1)_$(f2)_$(f3)_$(fname_add)\"), \n",
    "                        h_equalized_filtered_arr |>  transpose |> Array)\n",
    "                    end # target, fname_add\n",
    "                end # f3\n",
    "        end\n",
    "    end\n",
    "end\n",
    " \n",
    "main(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "\n",
    "println(isfile(\"LOSC_Event_tutorial.ipynb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14-element Array{Float64,1}:\n",
       " 1.0\n",
       " 0.7788007830714049\n",
       " 0.6065306597126334\n",
       " 0.4723665527410147\n",
       " 0.36787944117144233\n",
       " 0.2865047968601901\n",
       " 0.22313016014842982\n",
       " 0.1737739434504451\n",
       " 0.1353352832366127\n",
       " 0.10539922456186433\n",
       " 0.0820849986238988\n",
       " 0.06392786120670757\n",
       " 0.049787068367863944\n",
       " 0.03877420783172201"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.(-0.25*(0:13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
